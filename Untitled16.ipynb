{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAkNtUfPdH7DScbFgUSlu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mos2025uk-svg/Intelligent-Analysis-of-Pharmaceutical-Product-Descriptions-Using-NLP-and-Deep-Learning/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0coHcAcDYO7"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# NLP & ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Transformers\n",
        "!pip install -q transformers datasets torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Text processing\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset (Upload to Colab)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_excel(\"MID.xlsx\")  # adjust name if needed\n",
        "df = df[['description', 'therapeutic_class']].dropna()\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "qw3Uf-UvDlB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['clean_text'] = df['description'].apply(clean_text)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['therapeutic_class'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "ERvzmouEDnBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traditional ML Models (TF-IDF)\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1,2),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n"
      ],
      "metadata": {
        "id": "KK1deOrADtiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=200)\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred_lr = lr.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, pred_lr))\n",
        "print(classification_report(y_test, pred_lr))\n"
      ],
      "metadata": {
        "id": "-qnGriC0ELmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred_nb = nb.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, pred_nb))\n"
      ],
      "metadata": {
        "id": "MVkWNkhAEThl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = LinearSVC()\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred_svm = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, pred_svm))\n"
      ],
      "metadata": {
        "id": "8fX5vubNEXLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Learning Model (LSTM)\n",
        "tokenizer = Tokenizer(num_words=40000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = 200\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(40000, 128, input_length=max_len),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "2FnEuXZLEa8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "model.evaluate(X_test_pad, y_test)\n"
      ],
      "metadata": {
        "id": "or099LluEk_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer Model (BERT)\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer_bert(batch['text'], padding=True, truncation=True, max_length=128)\n",
        "\n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df[['clean_text', 'label']].rename(columns={'clean_text':'text'}))\n",
        "dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2)\n"
      ],
      "metadata": {
        "id": "O9E-lexSEq5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bert = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(le.classes_)\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=500,\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_bert,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test']\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "n0q0w5xiE1Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extractive (Simple)\n",
        "def structured_summary(text, max_sentences=3):\n",
        "    sentences = text.split('. ')\n",
        "    return '. '.join(sentences[:max_sentences])\n",
        "\n",
        "df['summary'] = df['description'].apply(structured_summary)\n",
        "df[['description', 'summary']].head()\n"
      ],
      "metadata": {
        "id": "VlmRincIE583"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Abstractive (Transformer)\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "sample_text = df['description'].iloc[0][:1024]\n",
        "summary = summarizer(sample_text, max_length=80, min_length=30, do_sample=False)\n",
        "summary\n"
      ],
      "metadata": {
        "id": "sAFz-JI0FIf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Comparison\n",
        "results = {\n",
        "    \"Model\": [\"Logistic Regression\", \"Naive Bayes\", \"SVM\", \"LSTM\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, pred_lr),\n",
        "        accuracy_score(y_test, pred_nb),\n",
        "        accuracy_score(y_test, pred_svm),\n",
        "        model.evaluate(X_test_pad, y_test, verbose=0)[1]\n",
        "    ]\n",
        "}\n",
        "\n",
        "pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "9CAO70--FRPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}